---
title: "01_dataset_creation"
author: "Miguel √Ångel Armengol de la Hoz"
date: "10/5/2019"
output: html_document
---

# Environment

```{r}
library(bigrquery)
library(summarytools)
library(readr)
library(stringr)
library(sqldf)
library(dplyr)
library(tableone)
library(Hmisc)
library(caret)
```


# Set up BigQuery related functions

This chunks also creates the run_query and get_sql function.

```{r setup, include=FALSE}
# Updated for our year
project_id <- "hst-953-2019"
options(httr_oauth_cache=FALSE)
# Function that takes in a sql command and runs it on bigquery
run_query <- function(query){
  data <- query_exec(query, project=project_id, use_legacy_sql=FALSE,max_pages = Inf)
  return(data)
}

# function for reading sql files
getSQL <- function(filepath){
  con = file(filepath, "r")
  sql.string <- ""

  while (TRUE){
    line <- readLines(con, n = 1)

    if ( length(line) == 0 ){
      break
    }

    line <- gsub("\\t", " ", line)

    if(grepl("--",line) == TRUE){
      line <- paste(sub("--","/*",line),"*/")
    }

    sql.string <- paste(sql.string, line)
  }

  close(con)
  return(sql.string)
}
```

# Loading queries and extracting the data

Loads all queries from the sql files in the extraction folder and runs them into RBigQuey to extract the data.

```{r}
apache_related<-run_query(getSQL("sql/apache_related.sql" ))
hct <- run_query(getSQL("sql/hct.sql" ))
# removes missing values
hct<-hct[complete.cases(hct),]

#Remove chronic AKI, creat, rrt patients, not necessary
# chronicAKI<-run_query(getSQL('sql/aki/chronicAKI.sql'))
# baseline_creat<-run_query(getSQL('sql/aki/baseline_creat.sql'))
# peakcreat48h<-run_query(getSQL('sql/aki/peakcreat48h.sql'))
# peakcreat7days<-run_query(getSQL('sql/aki/peakcreat7days.sql'))

# renal replacement therapy, not necessary
# first_rrt <-run_query(getSQL('sql/aki/first_rrt.sql'))

# BMI, weight, age, gender, type of unit that patients was admitted, location from admission, length of stay before admission, height
IO_exclusion <- run_query(getSQL('sql/IO_exclusion.sql'))
charlson_score <- run_query(getSQL('sql/charlson_score.sql'))

# gathers patientunitstayids with reliable fluid data
all_reliable <- run_query (getSQL("sql/all_reliable.sql"))

#demographic
demographic <- run_query(getSQL('sql/demographics.sql'))
demographic['body_surface_area']<-round(sqrt((demographic$height*demographic$weight) / 3600),2)

# SOFA variables
sofa_cv_day1_to_day4 <- run_query(getSQL("sql/sofa/sofa_cv_day1_to_day4.sql"))
sofa_renal_day1_to_day4 <- run_query(getSQL("sql/sofa/sofa_renal_day1_to_day4.sql"))
sofa_respi_day1_to_day4 <- run_query(getSQL("sql/sofa/sofa_respi_day1_to_day4.sql"))
sofa_3others_day1_to_day4 <- run_query(getSQL("sql/sofa/sofa_3others_day1_to_day4.sql"))

# Gathers sepsis patients and excludes patients that are bleeding
patient_inexcluded_icd9 <- run_query(getSQL('sql/patient_inexcluded_icd9.sql'))
# Sepsis patients according to angus criteria
sepsis <- run_query(getSQL('sql/sepsis.sql'))
patient_inexcluded_icd9 <- merge (sepsis, patient_inexcluded_icd9, all = TRUE)
# Fluid data
fluidIntake <- run_query(getSQL("sql/intake_output.sql"))
```

## Patients with sepsis and demographics and too much output

```{r}
# sepsis patients
selected_cohort<-inner_join(demographic,patient_inexcluded_icd9)

#exlusion based on output amount
selected_cohort<-sqldf('
SELECT * FROM 
selected_cohort
LEFT JOIN
IO_exclusion
USING
(patientunitstayid)
WHERE
IO_exclusion.patientunitstayid IS NULL
')
```

## SOFA eICU calcuation

```{r}
# sofa calculations
sofa_total_day1_to_day4<-sqldf('
SELECT selected_cohort.patientunitstayid,

max(sofa_cv_day1_to_day4.sofa_cv_day1 + sofa_respi_day1_to_day4.sofa_respi_day1 + sofa_renal_day1_to_day4.sofarenal_day1 + sofa_3others_day1_to_day4.sofacoag_day1 + sofa_3others_day1_to_day4.sofaliver_day1 + sofa_3others_day1_to_day4.sofacns_day1) AS sofatotal_day1,

max(sofa_cv_day1_to_day4.sofa_cv_day2 + sofa_respi_day1_to_day4.sofa_respi_day2 + sofa_renal_day1_to_day4.sofarenal_day2 + sofa_3others_day1_to_day4.sofacoag_day2 + sofa_3others_day1_to_day4.sofaliver_day2 + sofa_3others_day1_to_day4.sofacns_day2) AS sofatotal_day2,

max(sofa_cv_day1_to_day4.sofa_cv_day3 + sofa_respi_day1_to_day4.sofa_respi_day3 + sofa_renal_day1_to_day4.sofarenal_day3 + sofa_3others_day1_to_day4.sofacoag_day3 + sofa_3others_day1_to_day4.sofaliver_day3 + sofa_3others_day1_to_day4.sofacns_day3) AS sofatotal_day3,

max(sofa_cv_day1_to_day4.sofa_cv_day4 + sofa_respi_day1_to_day4.sofa_respi_day4 + sofa_renal_day1_to_day4.sofarenal_day4 + sofa_3others_day1_to_day4.sofacoag_day4 + sofa_3others_day1_to_day4.sofaliver_day4 + sofa_3others_day1_to_day4.sofacns_day4) AS sofatotal_day4

FROM 
selected_cohort
INNER JOIN sofa_cv_day1_to_day4 ON  selected_cohort.patientunitstayid = sofa_cv_day1_to_day4.patientunitstayid
INNER JOIN sofa_respi_day1_to_day4  ON selected_cohort.patientunitstayid = sofa_renal_day1_to_day4.patientunitstayid
INNER JOIN sofa_renal_day1_to_day4  ON selected_cohort.patientunitstayid = sofa_respi_day1_to_day4.patientunitstayid
INNER JOIN sofa_3others_day1_to_day4  ON selected_cohort.patientunitstayid = sofa_3others_day1_to_day4.patientunitstayid
GROUP BY selected_cohort.patientunitstayid
ORDER BY selected_cohort.patientunitstayid
')
```

## Fluid data

```{r}
# fluidIntake <- run_query(getSQL("sql/intake_output.sql" ))
#
fluidIntake<-fluidIntake[complete.cases(fluidIntake),]
fluidIntake<-fluidIntake%>%
  mutate( totalFluid = (intakes-outputs))
```


# Merging all datasets

```{r}
# We are using a left join to join them
cap_leak_index_dataset<-Reduce(function(...) merge(..., all.x=TRUE), list(
  selected_cohort
  ,apache_related
  ,hct
  ,fluidIntake
  # ,AKIlist_final
  ,charlson_score
  ,sofa_total_day1_to_day4
))

nrow(cap_leak_index_dataset)
a<-nrow(cap_leak_index_dataset)

# Ensures that patients have reliable fluid data

cap_leak_index_dataset<-sqldf('
SELECT * FROM
cap_leak_index_dataset
INNER JOIN
all_reliable
USING(patientunitstayid)
')
nrow(cap_leak_index_dataset)
b<-nrow(cap_leak_index_dataset)


a-b
# cap_leak_index_dataset<-sqldf('
# SELECT * FROM
# cap_leak_index_dataset
# INNER JOIN
# all_reliable
# USING(patientunitstayid)
# ')

# Ensures fluid intake is greater than 0.
cap_leak_index_dataset<-sqldf('
SELECT * FROM
cap_leak_index_dataset
WHERE totalFluid > 0 ')
```

# Creating new variables

```{r}
# merges the datasets
cap_leak_index_dataset<-cap_leak_index_dataset%>%
  mutate(
    # leaking_index=((mean_hct_24_36hrs/first_hct_6hrs)-1)*body_surface_area*1561
    leaking_index=((mean_hct_24_36hrs - first_hct_6hrs) / totalFluid) * body_surface_area
    ,delta_sofa=sofatotal_day4-sofatotal_day1
    ,q_leaking_index=as.numeric(cut2(leaking_index, g=4))
    ,q_delta_sofa=as.numeric(cut2(delta_sofa, g=4))
)

# makes variables a factor
cap_leak_index_dataset$q_leaking_index<-as.factor(cap_leak_index_dataset$q_leaking_index)
cap_leak_index_dataset$q_delta_sofa<-as.factor(cap_leak_index_dataset$q_delta_sofa)

# gender mapping
cap_leak_index_dataset<-cap_leak_index_dataset%>% filter(!(gender == ''))
cap_leak_index_dataset$gender[cap_leak_index_dataset$gender=='Male']<-1
cap_leak_index_dataset$gender[cap_leak_index_dataset$gender=='Female']<-2
# cap_leak_index_dataset$gender<-as.factor(cap_leak_index_dataset$gender)

# filters the missing data
cap_leak_index_dataset<-cap_leak_index_dataset%>%
  filter(!is.na(leaking_index))
cap_leak_index_dataset<-cap_leak_index_dataset%>%
  filter(!is.infinite(leaking_index))

# Remove outliers
outliers <- boxplot(cap_leak_index_dataset$leaking_index, plot=FALSE)$out
cap_leak_index_dataset <- cap_leak_index_dataset[-which(cap_leak_index_dataset$leaking_index %in% outliers),]
```

# Selecting/Imputing/removing data

```{r}
# creates the final dataset
selected_df <- cap_leak_index_dataset%>%dplyr::select(
 actualhospitalmortality
,age_fixed
,gender
,final_charlson_score
,apachescore
,q_leaking_index
)
selected_df<-selected_df[complete.cases(selected_df),]
```

# Dataset report

```{r}
cap_leak_index_dataset <- cap_leak_index_dataset[order(cap_leak_index_dataset$patientunitstayid),]
view(dfSummary(cap_leak_index_dataset))

sofamissing = sum(is.na(cap_leak_index_dataset$sofatotal_day1)) / length (cap_leak_index_dataset$sofatotal_day1)
bmimissing = sum(is.na(cap_leak_index_dataset$BMI)) / length (cap_leak_index_dataset$BMI)
weightmissing = sum(is.na(cap_leak_index_dataset$weight)) / length (cap_leak_index_dataset$weight)
```

# Export dataset

```{r}
write.csv(cap_leak_index_dataset,'cap_leak_index_dataset.csv')
```

# Selecting/Imputing/removing data

```{r}
table_df <- cap_leak_index_dataset %>%
  filter(!is.na(leaking_index) & !is.na(apachescore) & !is.na(q_leaking_index) & !is.na(final_charlson_score) & !is.na (actualhospitalmortality))
selected_df <- cap_leak_index_dataset%>%dplyr::select(
 actualhospitalmortality
,final_charlson_score
,apachescore
,q_leaking_index
)
selected_df<-selected_df[complete.cases(selected_df),]
```

# Train and test datasets creation

## Spliting de-identified data into testing and training, balanced version.

We want the data to be sampled randomly but always the same way and we want to be sure that train and test must be balanced.

```{r}
# Creating id for partition 
selected_df['id']<- seq.int(nrow(selected_df))
## set the seed to make our partition reproducible
set.seed(123)
# createDataPartition: "the random sampling is done within the levels of y when y is a factor in an attempt to balance the class distributions within the splits."
## 75% of the sample size
train_idx <- createDataPartition(as.factor(selected_df$actualhospitalmortality), times = 1, p = 0.75, list=F)

train <- selected_df[train_idx, ]
test <- selected_df[-train_idx, ]

#Checking outcome is actually balanced
round(prop.table(table(train$actualhospitalmortality)),2)
round(prop.table(table(test$actualhospitalmortality)),2)
```

## Separating datasets into outcome and exposures

```{r}
# train dataset
train_X<-train[, names(train)!= "actualhospitalmortality"]
train_Y<-train$actualhospitalmortality
  
# test dataset
test_X<-test[, names(test)!= "actualhospitalmortality"]
test_Y<-test$actualhospitalmortality 
```







